# -*- coding: utf-8 -*-
"""Copy of chiko01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TZB3kErfHGfpQZO6N0ulj8NMpXylGJK2
"""

import numpy as np
import pandas as pd
from keras.layers.core import Dense, Dropout, Activation, Flatten
from sklearn.model_selection import train_test_split
import os
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers.convolutional import Convolution2D
from keras.optimizers import RMSprop, Adam, Adadelta

from keras.layers import Conv2D, MaxPooling2D
import tensorflow as tf
import cv2

from google.colab import drive
drive.mount('/content/drive')

import pickle
DATA_PATH = "/content/drive/My Drive"

infile = open(DATA_PATH+"/x.pickle",'rb')
x = pickle.load(infile)
infile = open(DATA_PATH+"/y.pickle",'rb')
y = pickle.load(infile)

infile = open(DATA_PATH+"/x_test.pickle",'rb')
x_test = pickle.load(infile)
x_test=x_test-np.mean(x_test)
x_test=x_test/np.std(x_test)

y[:, [0,1]] = y[:, [0,1]]/128
y[:, [2,3]] = y[:, [2,3]]/96

x=x-np.mean(x)
x=x/np.std(x)

model=Sequential()
#first layer
model.add(Conv2D(32, kernel_size=(3, 3),
            activation='relu',
            input_shape=(96,128,3)))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))


model.add(Conv2D(64, kernel_size=(3, 3),
            activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))



model.add(Conv2D(128, kernel_size=(3, 3),
            activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

#flatten
model.add(Flatten())
#full connection
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.3))
          
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.4))
          
model.add(Dense(4, activation='relu'))
          
model.compile(loss='mse', optimizer=Adadelta(),metrics=['accuracy'])

num_samples = 14000
cv_size = 1000

train_data = x[0:num_samples]
train_target = y[0:num_samples]

x_train=train_data[0:13000]
y_train=train_target[0:13000]

x_valid=train_data[13000:14000]
y_valid=train_target[13000:14000]

model.fit(x_train, y_train, batch_size=50, nb_epoch=25, verbose=1, validation_data=(x_valid, y_valid) )

y_pred=model.predict(x_test,verbose=0)

y_pred[:, [0,1]] = y_pred[:, [0,1]]*128*5
y_pred[:, [2,3]] = y_pred[:, [2,3]]*96*5

df=pd.read_csv('/content/drive/My Drive/test.csv')
df['x1']= y_pred[:,0]
df['x2'] = y_pred[:,1]
df['y1'] = y_pred[:,2]
df['y2']= y_pred[:,3]
df.head()

from google.colab import files

df.to_csv('df1.csv',index=False)
files.download('df1.csv')

y_pred1=model.predict(x_valid,verbose=0)
y_pred1=y_pred1*5
y_pred1[:,[0,1]]=y_pred1[:,[0,1]]*128
y_pred1[:,[2,3]]=y_pred1[:,[2,3]]*96
y_pred1

df1=pd.DataFrame(y_pred1,columns=['x1','x2','y1','y2'])
from google.colab import files

df1.to_csv('valid3.csv',index=False)
files.download('valid3.csv')

